\chapter{Conclusions and Future Work}
\label{chp:b6}

We performed two user experiments followed by statistical analyses to get an in-depth understanding of image similarity for HDR images. We first collected a large number of human similarity responses via crowdsourcing, and then evaluated several image features with respect to the collected data. Evaluation is performed both on individual features and on their combination.
When combining features, two models both of which using logistic regression are considered. Although both models are found to perform comparably, the second one permits direct one-to-one comparison, making it more suitable for practical applications. We show one such application, namely style-based tone mapping that benefits from the experimental findings. Key observations obtained in our work are the following:

1. When properly tone mapped images are used as compared to using either original or linearly scaled HDR images, higher correlations with human responses are obtained.

2. Most tone mapping operators (TMOs) yield comparable performance.

3. Deeply learned features, in comparison to hand-crafted
features, correlate better with the human responses.

4. Among hand-crafted features, GIST yields the highest correlation, followed by color, luminance, and texture.

5. All of the estimated correlations for the second experiment are higher in comparison to those for the first experiment.

The first observation highlights the importance of using tone mapped data for HDR image similarity. While tone mapping is a lossy process, it brings the data to a more meaningful range for the computation of most features. However, some features are less dependent on tone mapping. For instance the texture feature represented by the histogram of oriented gradients is found to produce about the same correlation regardless of whether HDR or tone mapped data is used.

This is followed by the color feature represented by 2D chromaticity histogram. Among the hand-crafted features the largest difference is observed for luminance when tone mapped data is used. This can be expected as non-linear luminance compression often eliminates
large gaps in luminance histogram where little useful
information is present.

Perhaps unexpectedly, the second observation suggests that TMOs perform comparably. Although there exists a large number of TMO evaluation studies, we are not aware of any work that compares TMOs for the task of HDR image similarity. The lowest performing operator is found to be Pattanaik et al.â€™s [41] algorithm. It is, however, known that this algorithm highly depends on calibrated input data and viewing conditions as it tries to accurately model the human visual system.
As for the third observation, it is not surprising to find that features obtained from a DCNN [53] trained over a large image dataset [48] outperform simple hand-crafted features. Similar findings are reported by image retrieval studies conducted for low dynamic images [58,19]. For HDR images, our findings indicate that deep features are mostly useful if the images are tone mapped to the 8-bit per color channel domain first. This is also expected as the training data of DCNNs are comprised
of such images.

The fourth observation indicates that the GIST descriptor surpasses the texture, luminance, and color features for HDR image similarity. In addition to outperforming them, in fact, it performs surprisingly consistently across different processing types. Despite having a smaller correlation with the user data than the deep features, it exhibits less variability overall. This may be a desirable property as it appears to be minimally affected by how an HDR image is processed.
Pertaining to our last observation, it can be argued that seeking multiple consistent responses by the participants are important; not only for developing a more reliable model but also for assessing the correlation of different features with user responses. For instance, inspection of Tables 2 and 3 reveals that while deep features correlate better with the user responses, this difference is clearly magnified for the second experiment. In other words, as the experimental findings become more reliable the merits and drawbacks of different features becomes more noticeable.

We believe that our work simply scratches the surface of the HDR image similarity problem. The proposed models can be extended with different types of features. Further experiments which consider ranking and rating tasks as well as pairwise comparisons can be conducted. Evaluations may include DCNNs that are either fine-tuned or trained with HDR data from the ground up.