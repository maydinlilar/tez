\chapter{Discussion}
\label{chp:b6}

In this thesis, visual similarity problem for HDR images is investigated. To address the subjective nature of this problem, two user experiments are conducted and this experimental data is  statistically analysed to get an in-depth understanding of image similarity for HDR images. First, a large number of human similarity responses via crowdsourcing is collected, and then several image features with respect to the collected data is evaluated. Evaluation is performed both on individual features and on their combination. When combining features, two models both of which using logistic regression are considered. Although both models are found to perform comparably, the second one permits direct one-to-one comparison, making it more suitable for practical applications that relies on assessing similarity between images in a reliable way. 

One such application, that uses image similarity to tone map similar images in a similar way according to a style, namely style-based tone mapping is given. The first step of this tone mapping scheme is the creation of an artistic style by manually tone mapping a set of calibration images, then when an input HDR image is given, the similarity between this new image and calibration images are calculated, and the tone mapping parameters that will achieve the same style for the new images are estimated automatically from the parameters of the calibration images. Calibration images are picked from an HDR image dataset in a way that this set of images are dissimilar from each other as much as possible to cover the HDR image space as much as possible. At the beginning, a basic image similarity model are used for parameter estimation and then two new methods are proposed that improves this similarity model by incorporating the findings that are obtained from the user study. 

Key observations obtained in our work are the following:
%
\begin{enumerate}
\item When properly tone mapped images are used as compared to using either original or linearly scaled HDR images, higher correlations with human responses are obtained.
\item Most tone mapping operators (TMOs) yield comparable performance.
\item Deeply learned features, in comparison to hand-crafted features, correlate better with the human responses.
\item Among hand-crafted features, GIST yields the highest correlation, followed by color, luminance, and texture.
\item Combination of features performs better than individual features.
\item All of the estimated correlations for the second experiment are higher in comparison to those for the first experiment.
\item Applying the same tone mapping parameters directly to different HDR images yields different and mostly unpleasing tone mapping results.
\item It is time consuming to manually tone map HDR images according to a style.
\item Using the similarities to a small but diverse set of images, it is possible to consistently tone map HDR images according to a style, even if the images have different characteristics.
\item In the context of style-based tone mapping, better results are obtained when more descriptive features are used, feature distances calculated separately and suitable weights are used for features while calculating image similarities.
\end{enumerate}

The first observation highlights the importance of using tone mapped data for HDR image similarity. While tone mapping is a lossy process, it brings the data to a more meaningful range for the computation of most features. However, some features are less dependent on tone mapping. For instance the texture feature represented by the histogram of oriented gradients is found to produce about the same correlation regardless of whether HDR or tone mapped data is used. This is followed by the color feature represented by 2D chromaticity histogram. Among the hand-crafted features the largest difference is  observed for luminance feature when tone mapped data is used for representation. This can be expected as non-linear luminance compression often eliminates large gaps in luminance histogram where little useful information is present.

Perhaps unexpectedly, the second observation suggests that TMOs perform comparably. Although there exists a large number of TMO evaluation studies, we are not aware of any work that compares TMOs for the task of HDR image similarity. The lowest performing operator is found to be Pattanaik et al.'s~\cite{pattanaik2000time} algorithm. It is, however, known that this algorithm highly depends on calibrated input data and viewing conditions as it tries to accurately model the human visual system.

As for the third observation, it is not surprising to find that features obtained from a DCNN~\cite{simonyan2014very} trained over a large image dataset~\cite{russakovsky2015imagenet} outperform simple hand-crafted features. Similar findings are reported by image retrieval studies conducted for low dynamic images~\cite{wan2014deep,gordo2016deep}. For HDR images, our findings indicate that deep features are mostly useful if the images are tone mapped to the 8-bit per color channel domain first. This is also expected as the training data of DCNNs are comprised of such images.

The fourth observation indicates that the GIST descriptor surpasses the other hand-crafted features, texture, luminance, and color for HDR image similarity. In addition to outperforming them, in fact, it performs surprisingly consistently across different processing types. Despite having a smaller correlation with the user responses than the deep features, it exhibits less variability overall. This may be a desirable property for different applications as it appears to be minimally affected by how an HDR image is processed.

As expected, the fifth observation points to the findings that a combined feature with the learned weights performs better than individual features, which holds true for both of the logistic regression models. Although deeply learned features outperform the hand crafted features, and that is also observed with higher weights in the models, other features also contribute to the performance of the models. 

Regarding to the sixth observation, it can be argued that seeking multiple consistent responses by the participants are important; not only for developing a more reliable model but also for assessing the correlation of different features with user responses. For instance, inspection of Tables~\ref{tab:ind_correlation_p1} and~\ref{tab:ind_correlation_p2} reveals that while deep features correlate better with the user responses, this difference is clearly magnified for the second phase of the experiment. In other words, as the experimental findings become more reliable the merits and drawbacks of different features become more noticeable.

The seventh observation is, due to the vastly varying nature of HDR images, using the same set of tone mapping parameters that gives pleasing results for an image, may result with very poor rendering for another image. For example, since HDR images luminance values are boundless, a high cut-off value for a night scene might be very low for a day time scene, yielding with a really dark image that loses many details otherwise could be rendered.

The eighth observation states that, since tone mapping parameters can not be applied directly to different images, for each new image that depicts a different scene, the parameters need to be adjusted in a way that the resulting image follows the same style. This is a time consuming and not so straight forward process, searching for a set of parameters manually by adjusting parameters one by one, observing the effect on the resulting image and updating the parameters in a way that hopefully results with a rendering that is consistent with the other images. Keeping this observation in mind, the number of calibration images that need to be manually tone mapped are kept as small as possible.

The ninth observation features that although HDR images can be very diverse and for uncalibrated HDR images the same values do not correspond to the same physical or perceptual brightness, it is possible to tone map these images in a consistent way following a user defined style by using similar parameters for similar images. In style-based tone mapping, in order to achieve this, a small set of calibration images are used and the tone mapping parameters are estimated with the similarities between these calibration images and the input image. Although the number of calibration images are quite low, this is preferred since it directly effects the duration of manual style creation, the method is able to capture the style and consistently tone map different HDR images as presented in Figure~\ref{fig:gallery}. 

However, it should be noted that the selection of calibration images are important for the performance of the style-based tone mapping. The set of selected images should be as large as possible to be able to find a similar image in this set to the input HDR image. On the other hand, with a large the number of the calibration images, calibration phase, the style generation, will take too much time that the method become unpractical. Therefore, there is a trade off between the expressiveness and the number of calibration images. In order to keep the number of images as low as possible while keeping the expressiveness high, the calibration images are picked in a way that these images are dissimilar to each other as much as possible. In this thesis calibration images are hand selected from a clustered HDR dataset of natural images to be able to handle the most common HDR image types. Also, the calibration images capture varying sceneries like night, bright sunny day, cloudy day, sunset, indoor, outdoor etc. However, with this set of calibration images, this tone mapping scheme may not give successful results for computer generated scenes or modern art. For different domains, domain specific calibration images may give better results.

Finally, as the last observation, not surprisingly, the used similarity model has a direct effect on the performance of the application. In the initial version of style-based tone mapping which is described in Section~\ref{sec:operation}, the image representation consists of a single fused vector of histograms calculated from HSV color space and magnitude of gradients. To improve the image representation, these features are replaced with the features introduced in Chapter~\ref{chp:b3} and analyzed in Chapter~\ref{chp:b4} against the user responses. The first difference is using luminance as a separate feature represented as a higher resolution histogram with the motivation of luminance being one of the most important features in HDR tone mapping. Secondly, Lab color space is preferred over HSV color space due its perceptually uniform characteristic. Lastly, besides of low level image features, high performing features like GIST descriptor and deeply learned features are also included.

In addition to the image representation, the metrics that are used to estimate the distance between features are also plays an important role in image similarity. The distance metric used in the initial version of style-based tone mapping, given in Equation~\ref{eq:distance_metric} is used to calculate the distance between image features that are fused into a single vector. Instead, as given in Section~\ref{sec:improvements}, calculating the distances between features separately using the proper distance metrics yields better results. For example, EMD takes into account of bin proximity when calculating distances between features that are represented with a histogram, which makes it a more suitable metric.

Another point that needs consideration is the contribution of the image features to the similarity model when multiple image features are employed. In the initial version of the style-based tone mapping operator, all features are fused using the equal weights. On the other hand, as showed in Chapter~\ref{chp:b4}, a similarity model that using different weights for different features can be derived. With the conducted user experiment data, the weights for the features are estimated with a logistic regression and these weights are used for similarity calculation in style-based tone mapping, as described in Section~\ref{sec:all_features}. With all these modifications that are made to improve the similarity calculation of the style-based tone mapping operator, results that are more compatible with the given style and the image characteristics are obtained as shown in Figure~\ref{FigStyle}. 

While these modifications that improves the similarity model in a general sense yield with better tone mapping results, like in many other applications, it is possible to refine the results further by adding problem specific heuristics. In Section~\ref{sec:related_features}, instead of using all feature distances to estimate each tone mapping parameter, image features that are directly related with the tone mapping parameters are used for the estimation of tone mapping parameter and the features that do not directly relate to a tone mapping parameter added to the overall estimation. As shown in Figure~\ref{FigStyle} this approach results with capturing image characteristics better. 

Although, several style-based tone mapping results are provided in Section~\ref{sec:operation} and comparison of results with improved similarity models in Section~\ref{sec:improvements}, it is not straight forward to measure the performance of the proposed tone mapping methodology nor the improvements to it. From the style perspective, there is no ground truth that will allow to calculate the differences or compare image statistics. On the other hand, for improvements to the style-based tone mapping, some image statistics between resulting images can be calculated, like the change in mean brightness or contrast. However, image statistics do not directly translate to perception and even if the measured effects are also visible when results are compared, it does not imply better tone mapping results or compliance with the given style. As a future research direction, some perceptual experiments can be conducted to measure the performance of the proposed tone mapping methodology, in terms of depicting the given style or image quality of the tone mapped images or evaluating the effect of employed similarity models.  

